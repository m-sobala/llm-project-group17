from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# NEED TO FIX DOCUMENTATION

def load_summarizing_model_and_tokenizer(model_name: str):
    """
    Loads a pre-trained model and tokenizer for summarizing.

    Args:
        model_name (str): The name of the pre-trained sequence-to-sequence model.

    Returns:
        tuple: 
            - tokenizer: The tokenizer for the summarization model.
            - model: The sequence-to-sequence model.
    """
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
    return tokenizer, model


def summarize_text(model, text_file: str, max_length=150, min_length=40) -> str:
    """
    Summarizes the input text using a pre-trained sequence-to-sequence model.

    Args:
        model (transformers.PreTrainedModel): A pre-trained model for text summarization (e.g., T5, BART).
        text (str): The text file to summarize.

    Returns:
        str: A summary of the input text generated by the model.
    """
    # Read the text from the input file
    with open(text_file, 'r', encoding='utf-8') as file:
        text = file.read()

    # Load the summarization model
    tokenizer, model = load_summarizing_model_and_tokenizer(model)

    inputs = tokenizer.encode("summarize: " + text, return_tensors="pt", max_length=1024, truncation=True)
    summary_ids = model.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True)

    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)

    return summary

