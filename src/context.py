from utils import load_model_and_tokenizer


def summarize_text(model, text_file: str, max_length=150, min_length=40) -> str:
    """
    Summarizes the input text using a pre-trained sequence-to-sequence model.

    Args:
        model (transformers.PreTrainedModel): A pre-trained model for text summarization (e.g., T5, BART).
        text (str): The text file to summarize.

    Returns:
        str: A summary of the input text generated by the model.
    """
    # Read the text from the input file
    with open(text_file, 'r', encoding='utf-8') as file:
        text = file.read()

    # Load the summarization model
    tokenizer, model = load_model_and_tokenizer(model)

    inputs = tokenizer.encode("summarize: " + text, return_tensors="pt", max_length=1024, truncation=True)
    summary_ids = model.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True)

    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)

    return summary

